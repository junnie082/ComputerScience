# Computer Graphics

# 3D Basic

#### 2024.12.10.(화)

## [3D 그래픽스란 무엇인가?](https://blog.naver.com/bys_123/100043316977)

우리가 흔히 보는 컴퓨터 화면 속의 그림은 2차원이다. 화면 속의 그림은 많은 점으로 이루어져 있고 그 각각의 점들은 X와 Y축의 값으로 표현할 . 수있기 때문이다.

만약 사람의 얼굴 모습을 정면으로 그린다면 그것으로 끝이다. 그 사람의 옆모습이나 뒷모습을 보고 싶다고 해서 그 그림을 옆으로 돌릴 수는 없다.

따라서 다시 그림을 그려야만 그 사람의 옆모습을 볼 수 있다.

3차원으로 그림을 그린다면 어떨까?
그때는 화면에 보이는 물체의 모습을 점으로 그리지 않는다.

수많은 조그만 면으로 그린다. 이 면들이 모두 공중에 떠서 사람의 모습을 만들고 있는 것을 상상해 보자.

그리고 그 면들이 공중에서 떠 있는 위치는 X와 Y의 두 축만으로 나타낼 수 없으므로 Z축이라는 새로운 값이 필요하다.

이때 면들을 각각 `폴리곤(Polygon)`이라고 부른다.
실제로 컴퓨터에서 면은 대부분 삼각형으로 만들어진다.
이것을 `트라이앵글(Triangle)`이라고 부른다.
만약 사람의 모습을 좀 더 자사하게 그리고 싶다면 그 면의 개수를 많게 하면 된다.

우선 `모델링(Modeling)`이란 용어가 있다. 이것은 어떤 물체의 3차원적인 모습을 수치 데이터로 표현하는 것을 말한다.
물론 그 수치값은 X,Y,Z 축의 세 가지 값을 가진다. 사람의 머리를 모델링한다면 머리의 위쪽, 턱, 뒤통수 등 모든 부분을 다 모델링해야 한다. 그래야만 나중에 컴퓨터가 어느 방향에서 본 모습을 그리더라도 진짜처럼 보일 수 있다.

`렌더링(Rendering)`은 3차원으로 그려진 모델링 데이터를 모니터 화면에 보여주기 위해서 2차원으로 그려주는 것을 말한다. 어차피 모니터는 2차원 출력장치이므로 꼭 필요한 과정이 바로 렌더링이다.

3D 그래픽 소프트웨어나 하드웨어의 성능을 나타날 때에는 보통 초당 몇 개의 폴리곤이나 트라이앵글을 계산해낼 수 있는지를 가지고 따지곤 한다. 경우에 따라서는 3D 벡터를 시간당 얼마나 많이 처리할 수 있는지의 여부를 가지고 나타내기도 한다. 하지만 이런 것은 반드시 정확한 결과를 준다고 볼 수는 없으므로 그저 참고사항으로만 생각하는 것이 바람직하다.

`텍스쳐 매핑(Texture Mapping)`은 3D 그래픽 속의 2D 그림이다. 가령 3차원 그래픽 화면 안에 있는 사람이 어떤 사진을 들고 있다거나, 벽화가 벽에 걸려 있는 경우를 생각해 보자. 또는 하늘에 구름이 떠 있는 광경, 도로의 모습 같은 것들은 전혀 3차원 그래픽을 사용할 필요가 없는 것들이다. 이럴 때에는 아예 그런 것들을 일반 GIF나 TIFF 방식으로 저장되는 2D 그래픽 파일로 씌워주는 것이 편리하다. 이런 기술을 텍스쳐 매핑이라고 부른다.

## [[Computer Graphics] #1. 서론](https://choi-dan-di.github.io/computer-graphics/introduction/)

### 3차원 컴퓨터 그래픽스

`컴퓨터 그래픽스`란, 컴퓨터를 이용하여 영상(image)을 생성하는 작업을 의미한다. `3차원 컴퓨터 그래픽스`는 이 작업에서 3차원으로 표현된 물체를 입력으로 받아 2차원 영상으로 출력하는 작업을 의미한다. 이러한 2차원 영상을 `프레임(frame)`이라 하는데 이 프레임들을 연속적으로 보여주면 물체가 움직이는 듯한 느낌을 줄 수 있다.

그래픽스에는 크게 `실시간 그래픽스`와 `비실시간 그래픽스`로 나뉜다. 실시간 그래픽스의 대표적인 예는 게임이며 성능은 1초당 몇 프레임을 만들어낼 수 있느냐, 즉 `frames per second(fps)`로 측정할 수 있다. 보통 초당 30 프레임 이상을 만들어내야 한다. 게임 뿐 아니라 AR/VR 등도 실시간 그래픽스에 속한다.

반면, 비실시간 그래픽스는 영화에서 쓰이는 `특수 효과`가 대표적이다. 해당 작업은 실사 영상과 구분이 되지 않는 사진 사실적인 영상을 만들어내는 것이 목표이며 상당히 많은 연산을 수행한다.

두 그래픽스는 알고리즘으로 구분할 수 있으며, 앞으로 알아볼 내용은 주로 실시간 그래픽스에 관한 내용이다.

### 컴퓨터 그래픽스 제작 단계

컴퓨터 그래픽스는 보통 5단계로 구분된다.

`modeling` -> `rigging` -> `animation` -> `rendering` -> `post-processing`

모델링, 리깅, 애니메이션 제작 단계는 `그래픽 아티스트` 혹은 `그래픽 디자이너`가 오프라인에서 수행하는 단계이다.

만들어진 애니메이션 재생, 렌더링, 후처리의 단계는 `런타임(Run-Time)` 때 수행되며 컴퓨터가 자동으로 실행하는 단계이다.

### Modeling

`모델(Model)`이란, 컴퓨터가 이해하고 처리할 수 있는 형태로 표현한 물체를 의미한다. `모델링(Modeling)` 단계에서는 바로 이러한 모델들을 만들어 낸다.

보통 모델은 `폴리곤(Polygon; 다각형)`들로 구성이 되며, 이렇게 폴리곤으로 구성된 물체를 `폴리곤 메시(Polygon Mesh)`라고 한다. 다각형 중 삼각형이 가장 간단한 구조이므로 삼각형 메시가 가장 많이 쓰인다.

이렇게 만들어진 폴리곤 메시에 입혀서 시각적 사실성을 높여주는 `텍스쳐(Texture)` 제작도 모델링 과정에 속한다. 이러한 텍스쳐를 만들어 폴리곤 메시에 입히는 것은 `텍스쳐링(Texturing)`이라고 한다.

위의 이미지에서 왼쪽에 위치한 이미지가 `이미지 텍스쳐`의 한 예이고, 가장 간단하면서도 가장 많이 사용되는 텍스쳐 형식이다.

### Rigging

위에서 만든 모델의 움직임을 표현하고 싶을 때, 가장 간단하게 사용할 수 있는 것은 모델의 `골격(Skeleton)`을 구성한 후, 각각의 `뼈(bone)`를 움직이게 하는 것이다. 골격을 폴리곤 메시에 삽입하면 애니메이션을 입힐 수 있다.

애니메이션을 위해 폴리곤 메시와 스켈레톤의 상관 관계를 정하는 작업을 `리깅(Rigging)`이라고 한다.

### Animation

뼈를 이용한 애니메이션을 `스켈리탈 모션(Skeleton Motion)`이라 한다. `애니메이션(Animation)`은 리깅 단계를 거치고 난 폴리곤 메쉬의 애니메이션을 프레임 별로 설정해주는 단계이다. 기본적으로 며칠에서, 많게는 몇달이 걸릴 수도 있는 작업 단계이다. 모든 작업이 끝나고 나면 프레임 별로 애니메이션이 생성되게 될 것이고, 이렇게 만들어진 애니메이션은 런타임에 프레임 별로 재생이 된다.

### Rendering

`렌더링(Rendering)`은 런타임일 때 만들어진 모델을 애니메이트 시키는 과정이다. 앞서 모델링 단계에서 만들었던 텍스쳐가 입혀지는 과정인 `텍스쳐링(Texturing)`이 기본적으로 수행되어야 하고, 조금 더 사실적으로 묘사하기 위해 빛과 물체의 상호 작용을 처리하는 `라이팅(Lighting)`이 그 핵심을 이룬다. 라이팅을 적용시키면 그림자 등을 제작할 수 있다.

### Post-Processing

`후처리(Post-Processing)`은 렌더링과 같이 필수적인 단계는 아니고 `선택적으로 수행되는 단계`이다. 앞서 만들었던 결과물에 더하여 조금 더 사실적으로 표현하기 위해 수행된다. 빠른 속도로 진행되는 애니메이션의 경우, 한 프레임에 그 이전 프레임의 잔영을 남기면 시각적 사실성을 높일 수 있는데, 이를 `모션 블러(Motion Blur)`라 한다. 또한, 일반 사진과 같이 초점이 맞춰지는 영역 바깥 부분을 흐릿하게 처리하는 것도 `초점 심도(Depth of Field)`라 한다.

### Graphics API

위에서 보았던 단계 중, 그래픽 디자이너가 오프라인에서 수행하는 모델링, 리깅, 애니메이션 단계의 경우 Autodesk의 `3ds Max` 혹은 `Maya`와 같은 소프트웨어가 널리 쓰인다. 반면, 런타임 애니메이션, 렌더링, 후처리는 `응용 프로그램`에 의해 실행된다.

게임 같은 경우는 대체로 `게임 엔진(Game Engine)` 같은 툴을 많이 사용한다. 대표적으로 유니티(Unity)와 언리얼(Unreal)이 존재한다. 게임 엔진은 애니메이션, 렌더링, 후처리에 필요한 필수불가결한 요소들을 망라하는 개발 툴인데, 근래의 게임 엔진은 여기에 더불어 `물리 기반 시뮬레이션, 사운드, 인공지능` 등의 기능도 제공한다.

## | game program (app) |

## | game engine |

## | graphics API (OpenGL ES) |

| GPU |

게임 프로그램 아래에 게임 엔진이 있고, 게임 엔진 아래에 `그래픽스 인터페이스(Graphics API)`가 있다. 일반적으로 게임 엔진은 그래픽스 API에 의해 개발되며 가장 많이 쓰이는 두 가지 API는 `Direct3D`와 `OpenGL`이다.

- Direct3D: DirectX API의 구성 요소 중 하나로, 마이크로소프트 플랫폼에서만 쓸 수 있다.

- OpenGL: 국제 표준 단체인 크로노스 그룹(Khronos Group)에 의해 관리되며, 다양한 플랫폼에서 사용되는 표준 API이다.

모바일 기기를 위한 API로 `OpenGL` 기능의 일부로 정의된 `OpenGL ES(Embedded System)`도 존재한다.

그래픽스 API의 아래엔 `GPU(Graphics Processing Unit)`가 존재한다. 이러한 API는 그래픽스 응용에 필수적은 함수들을 제공하는데, 오늘날 이러한 함수들은 대부분 GPU 내에서 하드웨어로 구현이 되어 있다.

OpenGL 을 구동하면 GPU가 작업을 수행하게 된다. 즉, 그래픽스 API는 GPU에 대한 `소프트웨어 인터페이스`라 할 수 있다.

## [[CG - Modeling] Polygon mesh](https://woochan-autobiography.tistory.com/938)

모델링에서는 polygon mesh를 통해 물체를 표현한다고 하였다.

### 1. 그렇다면 왜 polygon을 사용해 물체를 표현하는 것일까?

컴퓨터 그래픽스는 물체를 표현하는데 굉장히 많은 병렬 연산을 필요로 한다. 이때 구를 예시로 들자면 무수히 많은 점들을 필요로 하고 각 점들에 대해서 연산을 한다면 구 하나를 표현하는데도 엄청난 연산을 필요로 할 것이다. 이러한 물리적 한계를 뛰어넘기 위해 일종의 해상도를 낮추는 방식으로(근사적 표현 방식으로) polygon mesh를 사용한다.

위의 구를 표현하기 위해서 모든 점을 표현하는 것이 아니라, 일정한 갯수의 점을 다각형으로 잇는다. 이러한 방법을 polygon mesh라고 한다. 대체로 일반적인 다각형은 처리하지 않고 삼격형 또는 사각형 mesh로 처리한다. 또한 gpu가 폴리곤 메시 처리에 최적화 되어 있기 때문에 다른 방식의 표현은 채택되기 어렵다.

여기서 이슈는 정점의 개수를 어느 정도로 할 것인가가 굉장히 중요한 이슈가 된다. 정점의 갯수가 해상도가 되기 때문이다.

해상도를 늘리는 걸 refinement, 줄이는 것을 simplification 이라고 한다. 위와 같은 `LOD(Level Of Detail)` 컨트롤은 그래픽스에서 상당히 중요한 주제 중 하나이다.

이러한 폴리곤 메시의 제작은 그래픽 디자이너가 3ds max 등을 이용해 제작하는데 간단한 경우를 보면 다음과 같다.

### 2. 그럼 실제로 polygon mesh가 컴퓨터 안에서 어떤 식으로 표현이 될까?

아래 그림을 보면 삼각형이 3개로 표현이 되고, 각각의 삼각형은 정점으로 정의되어 있다. 세 개의 꼭지점을 그대로 배열에 적어 놓는다.
모든 삼각형마다 정점을 배치를 하고, 3개씩 끊어서 읽으면 삼각형 정보를 모두 얻을 수 있다.

얼핏보면 굉장히 좋은 표현방식이지만, 어떤 vertex의 경우 여러번 중복이 된다. 위 그림에선 (1,0)이 3개의 폴리곤에서 모두 사용되므로 세번이나 적어야 한다는 단점이 있다. 이러한 단점을 극복하기 위해서 표현하는 방식으로는 vertex와 index를 분리하는 방법이 있다.

`vertex array와 index array를 따로 만들어서`, 위와 같은 적은 데이터로도 표현할 수 있게 한다. 사실 vertex array의 한 cell이 엄청나게 크다. 실제로 vertex array로 중복 공간을 차지하는 비율이 index array가 중복 공간을 차지하는 비율보다 크다. 그렇기 때문에 위와 같은 방법을 써야 한다.

### 3. Surface normal

다음으로 Surface normal을 보자. vertex array에는 position 정보 말고 여러가지 정보가 들어간다. 그 중 하나가 normal이고 우리 말로는 법선이라고 한다. 삼각형의 normal은 좌표를 알고 있을 때 외적(벡터곱)을 통해 간단하게 계산할 수 있다.

삼각형의 꼭지점이 <p1, p2, p3> 라고 주어진다면,

꼭지점을 이어서 v1, v2 벡터를 구한 후, 오른속 법칙으로 외적(v1 x v2)을 하면, 삼각형의 normal을 쉽게 구할 수 있다. 그런데 컴퓨터 그래픽스에서 모든 normal을 길이가 1인 unit vector로 표현하기 때문에 normalization 과정을 거친다.

그런데 삼각형의 꼭지점이 <p1, p2, p3>가 아니라, <p1, p3, p2> 라고 주어진다면 시계방향으로 주어진 것이다.

그러면 반대로 오른속 법칙을 적용해주면 되지만 방향은 반대가 된다. 물체 안쪽을 파고드는 normal이 구해진 것이다. 컴퓨터 그래픽스에서는 모든 normal이 물체 바깥으로 향하게 하는 것이 기본적인 관례이다.

따라서 시계 방향 (p->r->q)이 아닌, `반시계 방향(p->q->r)`으로 vertex array로 만들어준다.
그렇기 때문에 index array도 t2 삼각형은 [3,1,0] 순으로 저장한다. 시작점은 상관 없다.

표면의 normal은 여러 문제에서 중요한 역할을 하는데 대표적으로 빛의 표현 등에서 중요하게 된다.

### 4. Vertex normal

하지만 실제로 필요한 것은 표면의 normal 보다 `정점에서의 normal`이다.

`vertex(정점) normal`은 `주변 삼각형들의 normal 평균으로 구할 수 있다.`

아래 그림처럼 각 정점은 여러 개의 삼각형에 의해서 공유가 되는데, 삼각형 normal은 쉽게 구할 수 있다.

그 정점을 공유하는 삼각형 normal의 평균을 구하면, 그 정점의 normal을 얻을 수 있다. 물론 normalization은 해주어야 한다.

총 6개의 normal인 n1+n2+n3+n4+n5+n6 를 자기 자신으로 나누면 vertex normal을 구할 수 있다.

> vertex normal은 vertex array가 반드시 가져야 할 정보이다.

아래와 같이 vertex array (position, normal)와 index array로 나타낼 수 있다.

## [CG - Spaces and Transforms](https://woochan-autobiography.tistory.com/939)

### 1. Scaling (확대, 축소)

먼저 볼 것은 Scaling이다. Scaling은 우리말로 축소, 확대이다.
2차원에서의 scaling을 먼저 보자. 간단하게 행렬로 표현하면 아래와 같다.

- 2D scaling with the scaling factors, sx and sy

[sx 0] [x] = [sxx]
[0 sy] [y] [syy]

### 2. Rotation (회전)

p 벡터의 좌표가 나와있을 때, 회전이 이루어졌을 때도 p' 벡터의 좌표를 알 수 있다. 기본적으로 반시계 방향으로 회전했을 때를 구한다.

### 3. Translation (이동)

지금까지 본 Scaling(확대/축소)와 Rotation(회전)은 선형변환이다. 하지만 이동(translation)은 선형 변환이 아니므로 위와 같은 행렬의 곱으로 표현할 수 없다. 선형 변환과 달리 이동은 일반적으로 행렬의 덧셈으로 표현되는데 `동차좌표(homogeneous coordinate)`를 이용하면 행렬곱으로 나타낼 수 있게 된다.

### 3.1. Transform composition

homogeneous coordinates는 굉장히 유용하다.

90도 rotation도 x 축으로 7만큼의 translation을 위와 같이 표현할 수 있다.

먼저 쓰여지는 것이 오른쪽에 위치한다.

교환 법칙이 성립이 안됨을 유의하라.

이제 원점이 아닌 임의의 점을 상대로 rotation 해보자.

너무나 당연하게도 (5,2)를 넣었을 때 (3,4)로 가지 않는 것을 알 수 있다.

(5,2)를 회전축이 되는 (3,2)를 중심으로 회전하려면 원점으로 이동시켜 주어야 한다. 그리고 나서 회전한 후 다시 이동한만큼 원상 복구 해준다. 위의 식처럼 하나의 행렬로 표현할 수 있다.

세번째 행은 항상 (0,0,1)로 고정이므로, 이를 무시하고 첫번째, 두번째 행을 유시하자.
우리는 이제 2행 3열의 matrix에서 2행 2열까지를 L이라고 하고, 3열을 t라고 약칭할 것이다.

L은 이름이 암시하는 것처럼 Linear transform이 결합되어 있는 곳이다. 여기에는 입력으로 주어지는 translation이 못 들어간다. 세번째 column에만 개입될 수 있다.

translation은 3열에만 관련 있다.
이것의 장점은 Rotation -> Translation 순서로 곱해도, Translation -> Rotation 순서로 곱해도 같은 결과가 나오는 것이다.

즉, 교환법칙이 성립이 되어 버린다.
이것이 Affine transform의 장점이다.
결론! Affine transform은 선형변환과 이동을 포함하는 변환이다.

n차원 Affine transform은 n+1차원의 행렬로 표현되므로 2차원 변환은 3x3 행렬로 표현된다.

### 4. 3D 에서의 Transform

#### 4.1. 3D Scaling

이제 3차원을 보도록 하자. 3차원에서의 scaling도 2차원에서와 동일하다.

행렬의 대각성분을 scaling 해주면 된다.

#### 4.2. 3D Rotation

3D Rotation의 경우 2D와 조금 다르게 표현되는데 2D에서는 회전이 원점을 기준으로 반시계 방향으로 표현되는데, 3D의 경우 다양한 회전축 표현이 가능해진다.

대표적으로 x축 중심 Rotation과 z축 중심 Rotation을 보자.

x축을 기준으로 회전하는 주전자가 어떤 방식으로 회전하는지 직관적으로 알 수 있다.

y축 회전의 경우 Ry = mat3({cos, 0, sin}, {0, 1, 0}, {-sin, 0, cos}) 으로 표현된다.

2차원과 마찬가지로 CCW(Counter Clock Wise)의 경우 양수로 표현되고 CW는 음수로 표현할 수 있다.
반시계 방향이 디폴트이다.

#### 4.3. 3D Translation

이제 translation을 보도록 하자.
2차원과 마찬가지로 affine transform의 경우 n+1 차원 행렬을 통해 표현할 수 있다.
만약 점(x,y,z)에 대해서 (dx, dy, dz)만큼 이동을 하고 싶다면 다음과 같은 표현으로 이동할 수 있다.

### 4.4 Application: World Transform

이제 이러한 변환을 어디에 사용하는지 알아보자.

물론 변환 행렬은 물체를 이동하고 변형시키는 많은 곳에 사용될 수 있지만 가장 대표적인 하나의 과정은 world transform이다.

물체를 모델링하는데 사용하는 공간을 `object space`라고 하는데 이 object space는 개별 물체를 정의하는 공간이므로 실제로 표현하고자 하는 스크린의 이미지를 모두 표현할 수 없다. 즉, 개별 물체가 존재하는 공간을 object space라고 하고 표현하고 싶은 world가 존재하는 공간을 `world space`라고 하기 때문에 우리는 world transform을 통해 object space에 정의되었던 물체들을 world space로 변환시켜야 한다. 즉, 단일한 객체 몇가지를 같은 공간에 넣어야 한다. 이러한 변환을 world transform이라고 한다.

우리는 구를 2배 넓히고, 주전자를 Rotation, Translation 시켜서 World space에 옮기고 싶다고 하자.

먼저 y축을 중심으로 Rotation 시키고, Translation 해주자. 행렬곱을 하고나면, 위와 같은 행렬이 만들어진다. 주전다 주둥이 끝의 좌표를 통해 확인할 수 있다.

#### 4.5. 3D Affine Transform

이런 4x4 Affine transform에 있어서 항상 네번째 행은 (0,0,0,1)T이다.
나머지 3x4 행렬은 [L|t]로 표현되는데 왼쪽을 accumulated linear transform, 오른쪽을 accumulated translation으로 볼 수 있다.

다만 이때 L은 t의 영향을 받지 않지만 t는 L의 영향을 받게 된다. [L|t]로 변환된 행렬을 보면 L을 먼저 계산하고 t를 계산한 것으로 볼 수 있다. 즉 linear transform을 먼저 진행하고 translation한 형태가 된다.

### 5. Rotation and Object-space Basis

> Once an object is created, it is fixed within its object space. An object can be thought of as being stuck to its object space.

모델링이 끝나면, Object는 Object space와 결박되어 있어서 둘이 같이 움직인다. 분리가 안되고 붙어 있다.

> The object-space basis is {u, v, n}. The world-space basis (standard basis) is {e1, e2, e3}.

World transform의 결과는 object space를 world space에 맞추는 것으로 볼 수 있다. 즉, object는 자신의 object space와 일치하게 되어 이동한다. {e1, e2, e3}는 world space의 basis를, {u, v, n}은 object space의 basis를 나타낸다고 하면 world transform 이후 E=u, v, n가 된다. 하지만 이후 object를 회전시키면 world space의 basis {u, v, n}은 그대로 유지되나 object space의 basis {e1, e2, e3}는 회전한다.
이때 회전을 R이라고 하자. 회전 후 basis는 다음과 같이 변한다.

중요한 것은 위에서 Object는 Object space와 딱 붙어서 간다고 했다.
여기서 말하고자 하는 것은 회전된 물체의 방향은 Object space basis의 방향으로 특징 지을 수 있다는 것이다.

즉, 물체의 회전이 적용되면 물체의 방향이 바뀌다. 그런데 어떠한 방향을 가질지는 {u,v,n}을 가지고 묘사할 수 있다.

Object space basis인 {e1, e2, e3}로 표현된 Object를 Rotation해도, World space의 basis인 {u,v,n}으로 표현할 수 있는 것을 확인할 수 있다!
